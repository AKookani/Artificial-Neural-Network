% Solve a Pattern Recognition Problem with a Neural Network
% Script generated by Neural Pattern Recognition app
% Created 18-Mar-2021 00:04:45
%
% This script assumes these variables are defined:
%
%   SomervillHappinessSurvey2015 - input data.
%   D - target data.

x = DryBeanDataset';
t1 = Barbunya';
t2 = Bombay';
t3 = CALI';
t4 = DERMASON';
t5 = HOROZ';
t6 = Seker';
t7 = SIRA';

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainlm';  % Scaled conjugate gradient backpropagation.

% Create a Pattern Recognition Network
hiddenLayerSize = [25 20];
net1 = patternnet(hiddenLayerSize, trainFcn);
 net1.layers{1}.transferFcn = 'tansig';
 net1.layers{2}.transferFcn = 'tansig';
 net1.layers{3}.transferFcn = 'tansig';
 
hiddenLayerSize = [25 20];
net2 = patternnet(hiddenLayerSize, trainFcn);
 net2.layers{1}.transferFcn = 'tansig';
 net2.layers{2}.transferFcn = 'tansig';
 net2.layers{3}.transferFcn = 'tansig';
 
hiddenLayerSize = [25 20];
net3 = patternnet(hiddenLayerSize, trainFcn);
 net3.layers{1}.transferFcn = 'tansig';
 net3.layers{2}.transferFcn = 'tansig';
 net3.layers{3}.transferFcn = 'tansig';

hiddenLayerSize = [25 20];
net4 = patternnet(hiddenLayerSize, trainFcn);
 net4.layers{1}.transferFcn = 'tansig';
 net4.layers{2}.transferFcn = 'tansig';
 net4.layers{3}.transferFcn = 'tansig';

hiddenLayerSize = [25 20];
net5 = patternnet(hiddenLayerSize, trainFcn);
 net5.layers{1}.transferFcn = 'tansig';
 net5.layers{2}.transferFcn = 'tansig';
 net5.layers{3}.transferFcn = 'tansig';
 
hiddenLayerSize = [25 20];
net6 = patternnet(hiddenLayerSize, trainFcn);
 net6.layers{1}.transferFcn = 'tansig';
 net6.layers{2}.transferFcn = 'tansig';
 net6.layers{3}.transferFcn = 'tansig';
 
hiddenLayerSize = [25 20];
net7 = patternnet(hiddenLayerSize, trainFcn);
 net7.layers{1}.transferFcn = 'tansig';
 net7.layers{2}.transferFcn = 'tansig';
 net7.layers{3}.transferFcn = 'tansig';
% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net1.input.processFcns = {'removeconstantrows','mapminmax'};
net2.input.processFcns = {'removeconstantrows','mapminmax'};
net3.input.processFcns = {'removeconstantrows','mapminmax'};
net4.input.processFcns = {'removeconstantrows','mapminmax'};
net5.input.processFcns = {'removeconstantrows','mapminmax'};
net6.input.processFcns = {'removeconstantrows','mapminmax'};
net7.input.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net1.divideFcn = 'dividerand';  % Divide data randomly
net1.divideMode = 'sample';  % Divide up every sample
net1.divideParam.trainRatio = 70/100;
net1.divideParam.valRatio = 15/100;
net1.divideParam.testRatio = 15/100;

net2.divideFcn = 'dividerand';  % Divide data randomly
net2.divideMode = 'sample';  % Divide up every sample
net2.divideParam.trainRatio = 70/100;
net2.divideParam.valRatio = 15/100;
net2.divideParam.testRatio = 15/100;

net3.divideFcn = 'dividerand';  % Divide data randomly
net3.divideMode = 'sample';  % Divide up every sample
net3.divideParam.trainRatio = 70/100;
net3.divideParam.valRatio = 15/100;
net3.divideParam.testRatio = 15/100;

net4.divideFcn = 'dividerand';  % Divide data randomly
net4.divideMode = 'sample';  % Divide up every sample
net4.divideParam.trainRatio = 70/100;
net4.divideParam.valRatio = 15/100;
net4.divideParam.testRatio = 15/100;

net5.divideFcn = 'dividerand';  % Divide data randomly
net5.divideMode = 'sample';  % Divide up every sample
net5.divideParam.trainRatio = 70/100;
net5.divideParam.valRatio = 15/100;
net5.divideParam.testRatio = 15/100;

net6.divideFcn = 'dividerand';  % Divide data randomly
net6.divideMode = 'sample';  % Divide up every sample
net6.divideParam.trainRatio = 70/100;
net6.divideParam.valRatio = 15/100;
net6.divideParam.testRatio = 15/100;

net7.divideFcn = 'dividerand';  % Divide data randomly
net7.divideMode = 'sample';  % Divide up every sample
net7.divideParam.trainRatio = 70/100;
net7.divideParam.valRatio = 15/100;
net7.divideParam.testRatio = 15/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net1.performFcn = 'mse';  % Cross-Entropy
net2.performFcn = 'mse';  % Cross-Entropy
net3.performFcn = 'mse';  % Cross-Entropy
net4.performFcn = 'mse';  % Cross-Entropy
net5.performFcn = 'mse';  % Cross-Entropy
net6.performFcn = 'mse';  % Cross-Entropy
net7.performFcn = 'mse';  % Cross-Entropy

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net1.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};
net2.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};
net3.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};
net4.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};
net5.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};
net6.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};
net7.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotconfusion', 'plotroc'};

net1.trainParam.max_fail=6;
net2.trainParam.max_fail=6;
net3.trainParam.max_fail=6;
net4.trainParam.max_fail=6;
net5.trainParam.max_fail=6;
net6.trainParam.max_fail=6;
net7.trainParam.max_fail=6;


% Train the Network
[net1,tr1] = train(net1,x,t1);
[net2,tr2] = train(net2,x,t2);
[net3,tr3] = train(net3,x,t3);
[net4,tr4] = train(net4,x,t4);
[net5,tr5] = train(net5,x,t5);
[net6,tr6] = train(net6,x,t6);
[net7,tr7] = train(net7,x,t7);

% Test the Network
y1 = hardlim(net1(x));
t1 = hardlim(t1);
e1 = gsubtract(t1,y1);
performance1 = perform(net1,t1,y1);
tind1 = vec2ind(t1);
yind1 = vec2ind(y1);
percentErrors1 = sum(tind1 ~= yind1)/numel(tind1);

y2 = hardlim(net2(x));
t2 = hardlim(t2);
e2 = gsubtract(t2,y2);
performance2 = perform(net2,t2,y2);
tind2 = vec2ind(t2);
yind2 = vec2ind(y2);
percentErrors2 = sum(tind2 ~= yind2)/numel(tind2);

y3 = hardlim(net3(x));
t3 = hardlim(t3);
e3 = gsubtract(t3,y3);
performance3 = perform(net3,t3,y3);
tind3 = vec2ind(t3);
yind3 = vec2ind(y3);
percentErrors3 = sum(tind3 ~= yind3)/numel(tind3);

y4 = hardlim(net4(x));
t4 = hardlim(t4);
e4 = gsubtract(t4,y4);
performance4 = perform(net4,t4,y4);
tind4 = vec2ind(t4);
yind4 = vec2ind(y4);
percentErrors4 = sum(tind4 ~= yind4)/numel(tind4);

y5 = hardlim(net5(x));
t5 = hardlim(t5);
e5 = gsubtract(t5,y5);
performance5 = perform(net5,t5,y5);
tind5 = vec2ind(t5);
yind5 = vec2ind(y5);
percentErrors5 = sum(tind5 ~= yind5)/numel(tind5);

y6 = hardlim(net6(x));
t6 = hardlim(t6);
e6 = gsubtract(t6,y6);
performance6 = perform(net6,t6,y6);
tind6 = vec2ind(t6);
yind6 = vec2ind(y6);
percentErrors6 = sum(tind6 ~= yind6)/numel(tind6);

y7 = hardlim(net7(x));
t7 = hardlim(t7);
e7 = gsubtract(t7,y7);
performance7 = perform(net7,t7,y7);
tind7 = vec2ind(t7);
yind7 = vec2ind(y7);
percentErrors7 = sum(tind7 ~= yind7)/numel(tind7);

% Recalculate Training, Validation and Test Performance
trainTargets1 = t1 .* tr1.trainMask{1};
valTargets1 = t1 .* tr1.valMask{1};
testTargets1 = t1 .* tr1.testMask{1};
trainPerformance1 = perform(net1,trainTargets1,y1);
valPerformance1 = perform(net1,valTargets1,y1);
testPerformance1 = perform(net1,testTargets1,y1);

trainTargets2 = t2 .* tr2.trainMask{1};
valTargets2 = t2 .* tr2.valMask{1};
testTargets2 = t2 .* tr2.testMask{1};
trainPerformance2 = perform(net2,trainTargets2,y2);
valPerformance2 = perform(net2,valTargets2,y2);
testPerformance2 = perform(net2,testTargets2,y2);

trainTargets3 = t3 .* tr3.trainMask{1};
valTargets3 = t3 .* tr3.valMask{1};
testTargets3 = t3 .* tr3.testMask{1};
trainPerformance3 = perform(net3,trainTargets3,y3);
valPerformance3 = perform(net3,valTargets3,y3);
testPerformance3 = perform(net3,testTargets3,y3);

trainTargets4 = t4 .* tr4.trainMask{1};
valTargets4 = t4 .* tr4.valMask{1};
testTargets4 = t4 .* tr4.testMask{1};
trainPerformance4 = perform(net4,trainTargets4,y4);
valPerformance4 = perform(net4,valTargets4,y4);
testPerformance4 = perform(net4,testTargets4,y4);

trainTargets5 = t5 .* tr5.trainMask{1};
valTargets5 = t5 .* tr5.valMask{1};
testTargets5 = t5 .* tr5.testMask{1};
trainPerformance5 = perform(net5,trainTargets5,y5);
valPerformance5 = perform(net5,valTargets5,y5);
testPerformance5 = perform(net5,testTargets5,y5);

trainTargets6 = t6 .* tr6.trainMask{1};
valTargets6 = t6 .* tr6.valMask{1};
testTargets6 = t6 .* tr6.testMask{1};
trainPerformance6 = perform(net6,trainTargets6,y6);
valPerformance6 = perform(net6,valTargets6,y6);
testPerformance6 = perform(net6,testTargets6,y6);

trainTargets7 = t7 .* tr7.trainMask{1};
valTargets7 = t7 .* tr7.valMask{1};
testTargets7 = t7 .* tr7.testMask{1};
trainPerformance7 = perform(net7,trainTargets7,y7);
valPerformance7 = perform(net7,valTargets7,y7);
testPerformance7 = perform(net7,testTargets7,y7);
% View the Network
% view(net)

% Plots
% Uncomment these lines to enable various plots.
% figure, plotperform(tr1)
% figure, plottrainstate(tr1)
% figure, plotperform(tr2)
% figure, plottrainstate(tr2)
% figure, plotperform(tr3)
% figure, plottrainstate(tr3)
% figure, plotperform(tr4)
% figure, plottrainstate(tr4)
% figure, plotperform(tr5)
% figure, plottrainstate(tr5)
% figure, plotperform(tr6)
% figure, plottrainstate(tr6)
% figure, plotperform(tr7)
% figure, plottrainstate(tr7)
% figure, ploterrhist(e1,'Barbunya',e2,'Bombay',e3,'CALI',...
%     e4,'DERMASON',e5,'HOROZ',e6,'Seker',e7,'SIRA')
figure, plotconfusion(t1,y1,'Barbunya',t2,y2,'Bombay',t3,y3,'CALI',...
    t4,y4,'DERMASON',t5,y5,'HOROZ',t6,y6,'Seker',t7,y7,'SIRA')
figure, plotroc(t1,y1,'Barbunya',t2,y2,'Bombay',t3,y3,'CALI',...
    t4,y4,'DERMASON',t5,y5,'HOROZ',t6,y6,'Seker',t7,y7,'SIRA')

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net1,'myNeuralNetworkFunction');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net1,'myNeuralNetworkFunction','MatrixOnly','yes');
    y = myNeuralNetworkFunction(x);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(net1);
end
